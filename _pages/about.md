---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a fifth-year Ph.D. candidate at the Institute of Artificial Intelligence and Robotics ([IAIR](https://iair.xjtu.edu.cn/index.htm), Xi'an Jiaotong University (XJTU), where I pursue my doctoral studies under the supervision of Prof.[Le Wang](https://gr.xjtu.edu.cn/web/lewang). I also collaborate closely with Prof.[Sanping Zhou](https://gr.xjtu.edu.cn/web/spzhou), Prof.[Gang Hua](https://www.ganghua.org/) and Prof.[Wei Tang](https://www.cs.uic.edu/~tangw/).

Previously, I received my B.Eng. degree in Robotics Engineering from Harbin Institute of Technology. I am currently a visiting Ph.D. student with the Multimedia and Human Understanding Group (MHUG) at the University of Trento, under the supervision of [Nicu Sebe](https://scholar.google.com/citations?user=stFCYOAAAAAJ&hl=en).




# üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìù Selected Publications
<div class='paper-box'>
  <div class='paper-box-image'>
    <div class="badge pulse-accent">AAAI 2026</div>
    <img src='/images/humansense.png' alt="SAMPO" width="100%">
  </div>
  <div class='paper-box-text'>
    <h3>HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs</h3>
    <div class="authors">
      <strong>Zheng Qin*</strong>, Ruobing Zheng, Yabing Wang, Tianqi Li, Yi Yuan, Jingdong Chen, Le Wang
    </div>
    <div class="venue">AAAI26</div>
    <div class="links">
      <a href="https://digital-avatar.github.io/ai/HumanSense/" class="btn-accent">Project</a>
      <a href="https://arxiv.org/abs/2508.10576" class="btn-accent"><i class="fas fa-file-alt"></i> Paper</a>
      <a href="https://github.com/antgroup/HumanSense" class="btn-accent"><i class="fab fa-github"></i> Code</a>
    </div>
  </div>
</div>

# Publications 
- MotionTrack: Learning Robust Short-term and Long-term Motions for Multi-Object Tracking (CVPR 2023)  
  **Qin Z**, Zhou S, Wang L, Duan J, Hua G, Tang W.

- Towards Generalizable Multi-Object Tracking (CVPR 2024)  
  **Qin Z**, Wang L, Zhou S, Fu P, Hua G, Tang W.

- Referencing Where to Focus: Improving Visual Grounding with Referential Query (NeurIPS 2024)  
  Wang Y, Tian Z, Guo Q, **Qin Z**, Zhou S, Yang M, Wang L.

- RefDetector: A Simple yet Effective Matching-based Method for Referring Expression Comprehension (AAAI 2025)  
  Wang Y, Tian Z, **Qin Z**, Zhou S, Wang L.

- Towards Precise Embodied Dialogue Localization via Causality Guided Diffusion (CVPR 2025)  
  Wang H, Wang L, **Qin Z**, Wang Y, Hua G, Tang W.

- Versatile Multimodal Controls for Whole-Body Talking Human Animation (ACM MM 2025)  
  **Qin Z**, Zheng R, Wang Y, Li T, Zhu Z, Yang M, Yang M, Wang L.

- HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs (AAAI 2026)  
  **Qin Z**, Zheng R, Wang Y, Li T, Yuan Y, Chen J, Wang L.

- Single-Shot and Multi-Shot Feature Learning for Multi-Object Tracking (TMM 2024)  
  Li Y, Zhou S, **Qin Z**, Wang L, Wang J, Zheng N.

- Robust Noisy Label Learning via Two-Stream Sample Distillation (TMM 2025)  
  Bai S, Zhou S, **Qin Z**, Wang L, Zheng N.

- Semantic and Kinematics Guidance for RMOT (TMM 2025)  
  Li Y, Zhou S, **Qin Z**, Wang L.

- Injecting Position and Relation Prior for Dense Video Captioning (Submitted to TIP)  
  Li Y, Zhou S, **Qin Z**, Lin J, Sun X, Wu K, Wang L.

- From Mapping to Composing: A Two-Stage Framework for Zero-shot Composed Image Retrieval (Submitted to TCSVT)  
  Wang Y, Tian Z, Guo Q, **Qin Z**, Zhou S, Yang M, Wang L.

- Embracing Aleatoric Uncertainty: Generating Diverse 3D Human Motion (Submitted to TCSVT)  
  **Qin Z**, Wang L, Wang Y, Yang M, Rong C, Yang M, Zheng N.

- RSRNav: Reasoning Spatial Relationship for Image-Goal Navigation (Submitted to TCSVT)  
  **Qin Z**, Wang L, Wang Y, Zhou S, Hua G, Tang W.

- Spatial Matters: Position-Guided 3D Referring Expression Segmentation (Submitted to CVPR 2026)  
  Wang Y, Tian Z, Wang L, **Qin Z**, Zhou S.



# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.


# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìñ Educations
- *2025.09 - (now)*, Visiting Ph.D. student, Artificial Intelligence, University of Trento.
- *2021.09 - (now)*, Ph.D. student, Control Science and Engineering, Xi'an Jiaotong University. 
- *2017.09 - 2021.06*, B.S., Robotics Engineering, Harbin Institute of Technology

# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# Services
Reviewer for CVPR, ICCV, ICML, ECCV, ICLR, NIPS, ACM MM, AAAI, etc.
